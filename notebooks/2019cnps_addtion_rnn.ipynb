{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019cnps_addtion_rnn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_addtion_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 足し算を行う seq2seq モデルの実装\n",
        "\n",
        "入力 \"535+61\"\n",
        "出力 \"596\"\n",
        "\n",
        "埋め草文字として空白の繰り返しを用いる\n",
        "\n",
        "入力はオプションで反転させることができる。\n",
        "これは，多くの課題で成績が向上することが知られている。\n",
        "\n",
        "文献としては，[Learning to Execute](http://arxiv.org/abs/1410.4615) と\n",
        "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
        "\n",
        "理論的には、ソースとターゲットの間に短期的な依存関係が導入される。\n",
        "以下実行結果の要約\n",
        "\n",
        "* 2 桁 反転 足し算\n",
        "+ 1 層 LSTM 訓練データ 99% 正解率，\n",
        "\n",
        "*  3 桁 反転 足し算\n",
        "+ 1 層LSTM 訓練データ 99% 正解率\n",
        "\n",
        "* 4 桁 反転 足し算。\n",
        "+ 1 層 LSTM  99% 正解率\n",
        "\n",
        "* 5 桁 反転。\n",
        "+ 1 層 LSTM (128 HN)99% \n"
      ],
      "metadata": {
        "id": "nzfH3NFEy41w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyKVWd5s-iuK"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "# from six.moves import range"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLI6yoGe-iuR"
      },
      "source": [
        "class CharacterTable(object):\n",
        "    \"\"\"任意の文字集合が問題として与えられた時に\n",
        "    1. ワンホット 整数表現に符号化\n",
        "    2. ワンホット 整数表現をその文字出力に復号化\n",
        "    3. 出力として得られた確率ベクトルを，対応する文字に復号化\n",
        "    \"\"\"\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"文字表の初期化\n",
        "\n",
        "        引数\n",
        "            chars: 入力信号に現れる全文字集合\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"文字列 C のワンホット表現\n",
        "\n",
        "        引数\n",
        "            num_rows: ワンホット表現ベクトルを返す行数\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return ''.join(self.indices_char[x] for x in x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu5w9zuA-iuU"
      },
      "source": [
        "class colors:\n",
        "    ok = '\\033[92m'    # 正解表示用の色を指定\n",
        "    fail = '\\033[91m'  # 失敗表示用の色を指定\n",
        "    close = '\\033[0m'  # 表示色をデフォルトに戻す\n",
        "\n",
        "# 訓練に用いるパラメータ\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "INVERT = True\n",
        "\n",
        "# 入力の最大長は `数字+数字` で表す\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n",
        "\n",
        "# 入力に用いる文字と埋め草文字(空白)を指定\n",
        "chars = '0123456789+ '\n",
        "ctable = CharacterTable(chars)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ivig-G-iue"
      },
      "source": [
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print('データの生成...')\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
        "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
        "    a, b = f(), f()\n",
        "\n",
        "    # 既知の足し算問題をスキップ\n",
        "    # 同様に x+Y == Y+x のような問題もスキップ。ソートもする。\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "\n",
        "    # 常にMAXLENになるようにデータを空白で埋める\n",
        "    q = '{}+{}'.format(a, b)\n",
        "    query = q + ' ' * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # 回答 `ans` は最大で DIGITS + 1 のサイズ\n",
        "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
        "    if INVERT:\n",
        "        # 例えば '12+345 ' は ' 543+21' となる。\n",
        "        # 埋め草文字の空白注意\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(f'総問題数: {len(questions)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXyg6INT-iuk"
      },
      "source": [
        "print('ベクトル化...')\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool_)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool_)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA9FvRLm-iuo"
      },
      "source": [
        "# x の後半部分はほとんど大きな数字になるためデータ (x, y) をシャッフル\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcQjkK6p-ius"
      },
      "source": [
        "# データセットの 10% を検証データセットとして設定。検証データセットでは学習を行わない\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print('訓練データセット数:')\n",
        "print(f'入力データサイズ: {x_train.shape}')\n",
        "print(f'教師データサイズ:{y_train.shape}')\n",
        "\n",
        "print('検証データセット数:')\n",
        "print(f'入力データサイズ: {x_val.shape}')\n",
        "print(f'教師データサイズ: {y_val.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPXGhQJM-iux"
      },
      "source": [
        "# GRU や SimpleRNN を置き換えて実行してみること\n",
        "RNN = layers.LSTM\n",
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "LAYERS = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zaTTDf3-ivD",
        "outputId": "76a637eb-07d3-462f-c08d-236791c112a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('モデル作成...')\n",
        "model = Sequential()\n",
        "\n",
        "# RNN を使って入力配列を符号化し，HIDDEN_SIZE の出力を生成\n",
        "# 注：入力系列が可変長の場合には `input_shape=(None, num_feature)` を使用\n",
        "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
        "\n",
        "# 復号化器 RNN の入力として，最終時刻の隠れ層の状態を繰り返し与える。\n",
        "# RNN の最終時刻の隠れ層の状態を，各時間ステップで繰り返し提供。\n",
        "# すなわち，DIGITS + 1 回繰り返す。\n",
        "# 例えば DIGITS=3 の場合，最大出力は999+999=1998 となる。\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "\n",
        "# 復号化器 RNN は，複数層を重ねることも，単層にすることも可能\n",
        "for _ in range(LAYERS):\n",
        "    # `return_sequences=True` にすると，最後の出力だけでなく，これまでの全出力を (num_samples, timesteps, output_dim) という形で返す。\n",
        "    # これは，下記  `TimeDistributed` が最初の次元を `timesteps` と想定しているため，必要となる。\n",
        "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
        "\n",
        "# 入力の各時間スライスに全結合層を適用する。\n",
        "# 出力系列の各時刻に対して，どの文字を選択するかを決定するため\n",
        "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
        "model.add(layers.Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデル作成...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               72192     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 4, 12)            1548      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 4, 12)             0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3vy6Lvk-ivI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5eb968d-7f2c-4040-b65f-3bbde1b944a2"
      },
      "source": [
        "# モデルを世代ごとに学習させ，検証用データセットに対する予測値を表示する。\n",
        "for iteration in range(1, 200):\n",
        "    print()\n",
        "    print('-' * 50)\n",
        "    print('反復回数', iteration)\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=1, validation_data=(x_val, y_val))\n",
        "    \n",
        "    # ランダムに 10 個事例をサンプリングして表示\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print('問:', q[::-1] if INVERT else q)\n",
        "        print('答:', correct)\n",
        "        if correct == guess:\n",
        "            print(colors.ok + '正' + colors.close, end=\" \")\n",
        "        else:\n",
        "            print(colors.fail + '誤' + colors.close, end=\" \")\n",
        "        print(guess)\n",
        "        print('---')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "反復回数 1\n",
            "352/352 [==============================] - 20s 46ms/step - loss: 1.8863 - accuracy: 0.3208 - val_loss: 1.7765 - val_accuracy: 0.3449\n",
            "問: 35+276 \n",
            "答: 311 \n",
            "\u001b[91m誤\u001b[0m 139 \n",
            "---\n",
            "問: 54+691 \n",
            "答: 745 \n",
            "\u001b[91m誤\u001b[0m 109 \n",
            "---\n",
            "問: 2+691  \n",
            "答: 693 \n",
            "\u001b[91m誤\u001b[0m 138 \n",
            "---\n",
            "問: 549+52 \n",
            "答: 601 \n",
            "\u001b[91m誤\u001b[0m 109 \n",
            "---\n",
            "問: 355+94 \n",
            "答: 449 \n",
            "\u001b[91m誤\u001b[0m 109 \n",
            "---\n",
            "問: 337+298\n",
            "答: 635 \n",
            "\u001b[91m誤\u001b[0m 104 \n",
            "---\n",
            "問: 36+382 \n",
            "答: 418 \n",
            "\u001b[91m誤\u001b[0m 139 \n",
            "---\n",
            "問: 767+600\n",
            "答: 1367\n",
            "\u001b[91m誤\u001b[0m 107 \n",
            "---\n",
            "問: 87+153 \n",
            "答: 240 \n",
            "\u001b[91m誤\u001b[0m 108 \n",
            "---\n",
            "問: 71+746 \n",
            "答: 817 \n",
            "\u001b[91m誤\u001b[0m 108 \n",
            "---\n",
            "\n",
            "--------------------------------------------------\n",
            "反復回数 2\n",
            "352/352 [==============================] - 15s 43ms/step - loss: 1.7272 - accuracy: 0.3618 - val_loss: 1.6510 - val_accuracy: 0.3805\n",
            "問: 30+678 \n",
            "答: 708 \n",
            "\u001b[91m誤\u001b[0m 771 \n",
            "---\n",
            "問: 78+65  \n",
            "答: 143 \n",
            "\u001b[91m誤\u001b[0m 171 \n",
            "---\n",
            "問: 642+56 \n",
            "答: 698 \n",
            "\u001b[91m誤\u001b[0m 606 \n",
            "---\n",
            "問: 984+38 \n",
            "答: 1022\n",
            "\u001b[91m誤\u001b[0m 901 \n",
            "---\n",
            "問: 188+48 \n",
            "答: 236 \n",
            "\u001b[91m誤\u001b[0m 891 \n",
            "---\n",
            "問: 365+16 \n",
            "答: 381 \n",
            "\u001b[91m誤\u001b[0m 666 \n",
            "---\n",
            "問: 850+812\n",
            "答: 1662\n",
            "\u001b[91m誤\u001b[0m 1299\n",
            "---\n",
            "問: 730+971\n",
            "答: 1701\n",
            "\u001b[91m誤\u001b[0m 1519\n",
            "---\n",
            "問: 151+976\n",
            "答: 1127\n",
            "\u001b[91m誤\u001b[0m 1201\n",
            "---\n",
            "問: 69+320 \n",
            "答: 389 \n",
            "\u001b[91m誤\u001b[0m 391 \n",
            "---\n",
            "\n",
            "--------------------------------------------------\n",
            "反復回数 3\n",
            "352/352 [==============================] - 15s 43ms/step - loss: 1.5820 - accuracy: 0.4063 - val_loss: 1.5196 - val_accuracy: 0.4311\n",
            "問: 299+549\n",
            "答: 848 \n",
            "\u001b[91m誤\u001b[0m 800 \n",
            "---\n",
            "問: 593+61 \n",
            "答: 654 \n",
            "\u001b[91m誤\u001b[0m 600 \n",
            "---\n",
            "問: 450+122\n",
            "答: 572 \n",
            "\u001b[91m誤\u001b[0m 586 \n",
            "---\n",
            "問: 721+46 \n",
            "答: 767 \n",
            "\u001b[91m誤\u001b[0m 778 \n",
            "---\n",
            "問: 820+891\n",
            "答: 1711\n",
            "\u001b[91m誤\u001b[0m 1698\n",
            "---\n",
            "問: 62+44  \n",
            "答: 106 \n",
            "\u001b[91m誤\u001b[0m 12  \n",
            "---\n",
            "問: 401+63 \n",
            "答: 464 \n",
            "\u001b[91m誤\u001b[0m 468 \n",
            "---\n",
            "問: 619+29 \n",
            "答: 648 \n",
            "\u001b[91m誤\u001b[0m 662 \n",
            "---\n",
            "問: 91+532 \n",
            "答: 623 \n",
            "\u001b[91m誤\u001b[0m 504 \n",
            "---\n",
            "問: 556+563\n",
            "答: 1119\n",
            "\u001b[91m誤\u001b[0m 100 \n",
            "---\n",
            "\n",
            "--------------------------------------------------\n",
            "反復回数 4\n",
            "352/352 [==============================] - 15s 44ms/step - loss: 1.4476 - accuracy: 0.4577 - val_loss: 1.3918 - val_accuracy: 0.4697\n",
            "問: 28+350 \n",
            "答: 378 \n",
            "\u001b[91m誤\u001b[0m 397 \n",
            "---\n",
            "問: 566+176\n",
            "答: 742 \n",
            "\u001b[91m誤\u001b[0m 727 \n",
            "---\n",
            "問: 16+688 \n",
            "答: 704 \n",
            "\u001b[91m誤\u001b[0m 743 \n",
            "---\n",
            "問: 322+470\n",
            "答: 792 \n",
            "\u001b[91m誤\u001b[0m 907 \n",
            "---\n",
            "問: 65+814 \n",
            "答: 879 \n",
            "\u001b[91m誤\u001b[0m 757 \n",
            "---\n",
            "問: 917+45 \n",
            "答: 962 \n",
            "\u001b[91m誤\u001b[0m 901 \n",
            "---\n",
            "問: 24+531 \n",
            "答: 555 \n",
            "\u001b[91m誤\u001b[0m 597 \n",
            "---\n",
            "問: 46+683 \n",
            "答: 729 \n",
            "\u001b[91m誤\u001b[0m 747 \n",
            "---\n",
            "問: 907+40 \n",
            "答: 947 \n",
            "\u001b[91m誤\u001b[0m 901 \n",
            "---\n",
            "問: 404+972\n",
            "答: 1376\n",
            "\u001b[91m誤\u001b[0m 1432\n",
            "---\n",
            "\n",
            "--------------------------------------------------\n",
            "反復回数 5\n",
            "352/352 [==============================] - 15s 43ms/step - loss: 1.3081 - accuracy: 0.5108 - val_loss: 1.2515 - val_accuracy: 0.5355\n",
            "問: 335+1  \n",
            "答: 336 \n",
            "\u001b[91m誤\u001b[0m 335 \n",
            "---\n",
            "問: 450+308\n",
            "答: 758 \n",
            "\u001b[91m誤\u001b[0m 755 \n",
            "---\n",
            "問: 691+7  \n",
            "答: 698 \n",
            "\u001b[91m誤\u001b[0m 797 \n",
            "---\n",
            "問: 623+366\n",
            "答: 989 \n",
            "\u001b[91m誤\u001b[0m 100 \n",
            "---\n",
            "問: 20+476 \n",
            "答: 496 \n",
            "\u001b[91m誤\u001b[0m 599 \n",
            "---\n",
            "問: 215+763\n",
            "答: 978 \n",
            "\u001b[91m誤\u001b[0m 909 \n",
            "---\n",
            "問: 591+90 \n",
            "答: 681 \n",
            "\u001b[91m誤\u001b[0m 667 \n",
            "---\n",
            "問: 774+140\n",
            "答: 914 \n",
            "\u001b[91m誤\u001b[0m 909 \n",
            "---\n",
            "問: 637+29 \n",
            "答: 666 \n",
            "\u001b[91m誤\u001b[0m 767 \n",
            "---\n",
            "問: 741+991\n",
            "答: 1732\n",
            "\u001b[91m誤\u001b[0m 1710\n",
            "---\n",
            "\n",
            "--------------------------------------------------\n",
            "反復回数 6\n",
            "198/352 [===============>..............] - ETA: 6s - loss: 1.2200 - accuracy: 0.5465"
          ]
        }
      ]
    }
  ]
}